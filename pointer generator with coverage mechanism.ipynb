{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:31.850183Z",
     "iopub.status.busy": "2024-01-29T12:02:31.849815Z",
     "iopub.status.idle": "2024-01-29T12:02:34.972979Z",
     "shell.execute_reply": "2024-01-29T12:02:34.972146Z",
     "shell.execute_reply.started": "2024-01-29T12:02:31.850149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from typing import Callable, Optional\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:34.975573Z",
     "iopub.status.busy": "2024-01-29T12:02:34.975181Z",
     "iopub.status.idle": "2024-01-29T12:02:43.227800Z",
     "shell.execute_reply": "2024-01-29T12:02:43.227048Z",
     "shell.execute_reply.started": "2024-01-29T12:02:34.975534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pkbar\n",
      "  Downloading pkbar-0.5-py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pkbar) (1.18.1)\n",
      "Installing collected packages: pkbar\n",
      "Successfully installed pkbar-0.5\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pkbar\n",
    "import pkbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:43.229583Z",
     "iopub.status.busy": "2024-01-29T12:02:43.229291Z",
     "iopub.status.idle": "2024-01-29T12:02:50.357834Z",
     "shell.execute_reply": "2024-01-29T12:02:50.356785Z",
     "shell.execute_reply.started": "2024-01-29T12:02:43.229553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from rouge) (1.14.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.359769Z",
     "iopub.status.busy": "2024-01-29T12:02:50.359464Z",
     "iopub.status.idle": "2024-01-29T12:02:50.369377Z",
     "shell.execute_reply": "2024-01-29T12:02:50.368269Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.359731Z"
    }
   },
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    hidden_size: int = 150  \n",
    "    dec_hidden_size: Optional[int] = 200  \n",
    "    embed_size: int = 100 \n",
    "    eps=1e-31\n",
    "    batch_size=16 \n",
    "    enc_bidi = True \n",
    "    enc_rnn_dropout = 0.1 \n",
    "    enc_attn = True \n",
    "    dec_attn = True \n",
    "    pointer = True \n",
    "    dec_in_dropout=0.1\n",
    "    dec_rnn_dropout=0.1\n",
    "    dec_out_dropout=0.1\n",
    "    max_src_len: int = 65 \n",
    "    max_tgt_len: int = 15  \n",
    "    vocab_min_frequency: int = 3\n",
    "    embed_file: Optional[str] = 'C:/Users/Nirmal/Documents/Python Scripts/glove.6B.100d.txt'  \n",
    "    data_path: str = 'C:/Users/Nirmal/Documents/Python Scripts/cl_train_news_summary_more.csv'\n",
    "    val_data_path: Optional[str] = 'C:/Users/Nirmal/Documents/Python Scripts/cl_train_news_summary_more.csv'\n",
    "    test_data_path: str = 'C:/Users/Nirmal/Documents/Python Scripts/cl_valid_news_summary_more.csv'\n",
    "    resume_train = False\n",
    "    encoder_weights_path='encoder_sum.pt'\n",
    "    decoder_weights_path='decoder_sum.pt'\n",
    "    encoder_decoder_adapter_weights_path='adapter_sum.pt'\n",
    "    losses_path='val_losses.pkl'\n",
    "    print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.372666Z",
     "iopub.status.busy": "2024-01-29T12:02:50.372363Z",
     "iopub.status.idle": "2024-01-29T12:02:50.385932Z",
     "shell.execute_reply": "2024-01-29T12:02:50.384988Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.372622Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_tokenizer(text, lower=False, newline=None):\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    if newline is not None:\n",
    "        text = text.replace('\\n', ' ' + newline + ' ')\n",
    "        return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.389203Z",
     "iopub.status.busy": "2024-01-29T12:02:50.388805Z",
     "iopub.status.idle": "2024-01-29T12:02:50.411186Z",
     "shell.execute_reply": "2024-01-29T12:02:50.410421Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.389163Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    PAD = 0\n",
    "    SOS = 1\n",
    "    EOS = 2\n",
    "    UNK = 3\n",
    "\n",
    "def __init__(self):\n",
    "    self.word2index = {}\n",
    "    self.word2count = Counter()\n",
    "    self.reserved = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "    self.index2word = self.reserved[:]\n",
    "    self.embeddings = None\n",
    "\n",
    "def add_words(self, words):\n",
    "    for word in words:\n",
    "  \n",
    "      if word not in self.word2index:\n",
    "\n",
    "        self.word2index[word] = len(self.index2word)\n",
    "\n",
    "        self.index2word.append(word)\n",
    "\n",
    "    self.word2count.update(words)\n",
    "  \n",
    "  def load_embeddings(self, file_path: str, dtype=np.float32) -> int:\n",
    "    ''' Load the embedding vectors from a file into the vocabulary'''\n",
    "    num_embeddings = 0\n",
    "    vocab_size = len(self)\n",
    "    with open(file_path, 'rb') as f:\n",
    "        for line in f:\n",
    "            line = line.split()\n",
    "            word = line[0].decode('utf-8')\n",
    "\n",
    "            idx = self.word2index.get(word)\n",
    "        if idx is not None:\n",
    "            vec = np.array(line[1:], dtype=dtype)\n",
    "        if self.embeddings is None:\n",
    "            n_dims = len(vec)\n",
    "            self.embeddings = np.random.normal(np.zeros((vocab_size, n_dims))).astype(dtype)\n",
    "            self.embeddings[self.PAD] = np.zeros(n_dims)\n",
    "            self.embeddings[idx] = vec\n",
    "            num_embeddings += 1\n",
    "            return num_embeddings\n",
    "\n",
    "def save_to_file(self, filename):\n",
    "    ''' Save the Vocab object to a file'''\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(self,f) \n",
    "\n",
    "def __getitem__(self, item):\n",
    "    ''' Get the next item when iterating over the instance'''\n",
    "    if type(item) is int:\n",
    "        return self.index2word[item]\n",
    "    return self.word2index.get(item, self.UNK)\n",
    "\n",
    "def __len__(self):\n",
    "    ''' Return the length of the instance or vocabulary'''\n",
    "    return len(self.index2word)\n",
    "\n",
    "\n",
    "def load_vocab(filename):\n",
    "    ''' Load a Vocab instance from a file'''\n",
    "    with open(filename,'rb') as f:\n",
    "        v = pickle.load(f)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.413220Z",
     "iopub.status.busy": "2024-01-29T12:02:50.412847Z",
     "iopub.status.idle": "2024-01-29T12:02:50.434120Z",
     "shell.execute_reply": "2024-01-29T12:02:50.433115Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.413184Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, filename: str, tokenize: Callable=simple_tokenizer, max_src_len: int=None,\n",
    "               max_tgt_len: int=None, max_rows: int=None, truncate_src: bool=False, truncate_tgt: bool=False):\n",
    "    print(\"Reading dataset %s...\" % filename, end=' ', flush=True)\n",
    "    \n",
    "    self.filename = filename\n",
    "    self.pairs = []\n",
    "    self.src_len = 0\n",
    "    self.tgt_len = 0\n",
    "    self.max_rows = max_rows\n",
    "\n",
    "    if max_rows is None:\n",
    "        df = pd.read_csv(filename, encoding='utf-8')\n",
    "    else:\n",
    "        df = pd.read_csv(filename, encoding='utf-8', nrows=max_rows\n",
    "                        )\n",
    "\n",
    "    sources = df['text'].apply(lambda x : tokenize(x))\n",
    "\n",
    "    if truncate_src:\n",
    "        sources = [src[:max_src_len] if len(src)>max_src_len else src for src in sources]\n",
    "\n",
    "    targets = df['summary'].apply(lambda x : tokenize(x))\n",
    "\n",
    "    if truncate_tgt:\n",
    "        targets = [tgt[:max_tgt_len] if len(tgt)>max_tgt_len else tgt for tgt in targets]\n",
    "        \n",
    " \n",
    "    src_length = [len(src)+1 for src in sources]\n",
    "    tgt_length = [len(tgt)+1 for tgt in targets]\n",
    "\n",
    "    max_src = max(src_length)\n",
    "    max_tgt = max(tgt_length)\n",
    "\n",
    "    self.src_len = max_src\n",
    "    self.tgt_len = max_tgt\n",
    "\n",
    "    self.pairs.append([(src, tgt, src_len, tgt_len) for src,tgt,src_len,tgt_len in zip(sources,targets,src_length,tgt_length)])\n",
    "    self.pairs = self.pairs[0]\n",
    "    print(\"%d pairs.\" % len(self.pairs))\n",
    "\n",
    "def build_vocab(self, min_freq, embed_file: str=None) -> Vocab:\n",
    "    \n",
    "    total_words=[src+tgr for src,tgr,len_src,len_tgr in self.pairs]\n",
    "    total_words = [item for sublist in total_words for item in sublist]\n",
    "    word_counts = Counter(total_words)\n",
    "    vocab=Vocab()\n",
    "    for word,count in word_counts.items():\n",
    "        if(count>min_freq):\n",
    "            vocab.add_words([word])  \n",
    "    count = vocab.load_embeddings(embed_file)\n",
    "    print(\"%d pre-trained embeddings loaded.\" % count)\n",
    "\n",
    "    return vocab  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.435823Z",
     "iopub.status.busy": "2024-01-29T12:02:50.435441Z",
     "iopub.status.idle": "2024-01-29T12:02:50.447531Z",
     "shell.execute_reply": "2024-01-29T12:02:50.446836Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.435784Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(nn.Module):\n",
    "    ''' A Dataset Class where we store all the data needed during the training phase'''\n",
    "    \n",
    "    def __init__(self, src_sents, trg_sents, vocab):\n",
    "        self.src_sents = src_sents\n",
    "        self.trg_sents = trg_sents\n",
    "        self.vocab=vocab\n",
    "        self._len = len(src_sents)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ''' Return the ith items from the object\n",
    "            Input:\n",
    "            - Index: integer, index of the items to return\n",
    "            Output:\n",
    "            - a dictionary with keys x the source texts, y the targets, \n",
    "              x_len length of source texts, y_len the length of targets\n",
    "        '''\n",
    "        return {'x':self.src_sents[index], \n",
    "                'y':self.trg_sents[index], \n",
    "                'x_len':len(self.src_sents[index]), \n",
    "                'y_len':len(self.trg_sents[index])}\n",
    "    \n",
    "    def __len__(self):\n",
    "        ''' Return the length of the object'''\n",
    "        return self._len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.448758Z",
     "iopub.status.busy": "2024-01-29T12:02:50.448496Z",
     "iopub.status.idle": "2024-01-29T12:02:50.466040Z",
     "shell.execute_reply": "2024-01-29T12:02:50.465229Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.448726Z"
    }
   },
   "outputs": [],
   "source": [
    "def tensorize(vocab, tokens):\n",
    "    ''' Convert the tokens received to a tensor '''\n",
    "    return torch.tensor([vocab[token] for token in tokens])\n",
    "\n",
    "def pad_sequence(vectorized_sent, max_len):\n",
    "    ''' Padding the sentence (tensor) to max_len '''\n",
    "    pad_dim = (0, max_len - len(vectorized_sent))\n",
    "    return F.pad(vectorized_sent, pad_dim, 'constant').tolist()\n",
    "\n",
    "def preprocess(x,y,p,vocab):\n",
    "    ''' Prepare a source text x and a target summary y: convert them to tensors,\n",
    "        pads the sentences to its max length.\n",
    "    '''\n",
    "    tensors_src = tensorize(vocab, x)\n",
    "    tensors_trg = tensorize(vocab, y) \n",
    "    return {'x':pad_sequence(tensors_src, p.max_src_len), \n",
    "          'y':pad_sequence(tensors_trg, p.max_tgt_len), \n",
    "          'x_len':len(tensors_src), \n",
    "          'y_len':len(tensors_trg)}\n",
    "\n",
    "def sort_batch_by_len(data_dict,p,vocab):\n",
    "    ''' Return a batch of sentences processed and ordered by its length\n",
    "    '''\n",
    "    data=[]\n",
    "    res={'x':[],'y':[],'x_len':[],'y_len':[]}\n",
    "    for i in range(data_dict['x_len']):\n",
    "        data.append(preprocess(data_dict['x'][i],data_dict['y'][i],p,vocab))\n",
    "    for i in range(len(data)):\n",
    "        res['x'].append(data[i]['x'])\n",
    "        res['y'].append(data[i]['y'])\n",
    "        res['x_len'].append(len(data[i]['x']))\n",
    "        res['y_len'].append(len(data[i]['y']))  \n",
    "    \n",
    "    sorted_indices = np.array(res['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:[_tensor[i] for i in sorted_indices]\n",
    "                  for name, _tensor in res.items()}\n",
    "    return data_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.467580Z",
     "iopub.status.busy": "2024-01-29T12:02:50.467217Z",
     "iopub.status.idle": "2024-01-29T12:02:50.482455Z",
     "shell.execute_reply": "2024-01-29T12:02:50.481655Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.467543Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, bidi=True, rnn_drop: float=0):\n",
    "    super(EncoderRNN, self).__init__()\n",
    "\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.num_directions = 2 if bidi else 1\n",
    "\n",
    "    self.gru = nn.GRU(embed_size, hidden_size, bidirectional=bidi, dropout=rnn_drop)\n",
    "\n",
    "def forward(self, embedded,hidden,input_lengths=None):\n",
    "    ''' Run a Forward pass of the encoder to return outputs\n",
    "        Input:\n",
    "        - embedded: tensor, the embedding of the input data (word of the soure text)\n",
    "        - hidden: a tensor, the previous hidden state of the encoder\n",
    "        - input:lengths: a list of integers, length of the inputs \n",
    "    '''\n",
    "    if input_lengths is not None:\n",
    "        embedded = pack_padded_sequence(embedded, input_lengths,batch_first=True)\n",
    "    \n",
    "    output, hidden = self.gru(embedded,hidden)\n",
    "    \n",
    "    if input_lengths is not None:\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "    if self.num_directions > 1:\n",
    "        batch_size = hidden.size(1)\n",
    "        hidden = hidden.transpose(0, 1).contiguous().view(1, batch_size, self.hidden_size * self.num_directions)\n",
    "    return output, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size, device):\n",
    "        return torch.zeros(self.num_directions, batch_size, self.hidden_size, device=device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.484116Z",
     "iopub.status.busy": "2024-01-29T12:02:50.483804Z",
     "iopub.status.idle": "2024-01-29T12:02:50.519627Z",
     "shell.execute_reply": "2024-01-29T12:02:50.518688Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.484089Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, enc_attn=True, dec_attn=True,\n",
    "               enc_attn_cover=True, pointer=True,\n",
    "               in_drop: float=0, rnn_drop: float=0, out_drop: float=0, enc_hidden_size=None,\n",
    "               epsilon: float=0.0, device: str=\"cpu\"):\n",
    "    ''' Initialize the decoder instance defining its parameters:\n",
    "            Input:\n",
    "                - vocab_size: integer, number of words in the vocabulary \n",
    "                - embed_size: integer, size of the embedding layer\n",
    "                - hidden_size: integer, size of the hidden layer (Hyperparameter)\n",
    "                - enc_attn: activate the attention in the encoder\n",
    "                - dec_attn: activate the attention in the decoder\n",
    "                - enc_attn_cover: activate the coverage mechanism in the attention\n",
    "                - pointer: activate the pointer generation\n",
    "                - in_drop: dropout probability to apply to the input of the decoder\n",
    "                - rnn_drop: dropout probability to apply to the GRU layer of the decoder\n",
    "                - out_drop: dropout probability to apply to the output of the decoder\n",
    "                - enc_hidden_size: dimension if the hidden state of the encoder\n",
    "                - epsilon: float\n",
    "                - device: cpu or gpu, device to store the tensors\n",
    "    '''\n",
    "\n",
    "    super(DecoderRNN, self).__init__()\n",
    "    self.vocab_size = vocab_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.combined_size = hidden_size\n",
    "    self.device = device\n",
    "    self.eps = epsilon\n",
    "    self.in_drop = nn.Dropout(in_drop) if in_drop > 0 else None\n",
    "    self.gru = nn.GRU(embed_size, hidden_size, dropout=rnn_drop)\n",
    "    \n",
    "    if not enc_hidden_size: enc_hidden_size = self.hidden_size\n",
    "    self.enc_bilinear = nn.Bilinear(hidden_size, enc_hidden_size, 1)\n",
    "    \n",
    "    self.combined_size += enc_hidden_size\n",
    "    if enc_attn_cover:\n",
    "        self.cover_weight = nn.Parameter(torch.rand(1))\n",
    "        self.dec_bilinear = nn.Bilinear(self.hidden_size, self.hidden_size, 1)\n",
    "        self.combined_size += self.hidden_size\n",
    "        self.out_drop = nn.Dropout(out_drop) if out_drop > 0 else None\n",
    "        self.ptr = nn.Linear(self.combined_size, 1)\n",
    "        self.out = nn.Linear(self.combined_size, vocab_size)\n",
    "\n",
    "def forward(self, embedded, hidden, encoder_hidden=None, decoder_states=None, coverage_vector=None, *,\n",
    "              encoder_word_idx=None, ext_vocab_size: int=None, log_prob: bool=True):\n",
    "    ''' Run a Forward pass of the decoder to return outputs\n",
    "        Input:\n",
    "        - embedded: tensor, the embedding of the input data (decoder output in the last step\n",
    "        - hidden: a tensor, the previous hidden state of the decoder\n",
    "        - decoder_states: tensor, hidden state of the decoder in the last step\n",
    "        - coverage_vector: tensor, coverage vector at this step\n",
    "        - encoder_word_idx: tensor, indexes of the words in the source text\n",
    "        - ext_vocab_size: integer, vocabulary size of the extended vocabulary\n",
    "        - log_prob: bool, use of Log Softmax or Softmax in the output\n",
    "    '''\n",
    "    batch_size = embedded.size(0)\n",
    "    combined = torch.zeros(batch_size, self.combined_size, device=self.device)\n",
    "    if self.in_drop: embedded = self.in_drop(embedded)\n",
    "    output, hidden = self.gru(embedded.unsqueeze(0), hidden)\n",
    "    combined[:, :self.hidden_size] = output.squeeze(0)        \n",
    "    offset = self.hidden_size\n",
    "    enc_attn, prob_ptr = None, None\n",
    "\n",
    "    num_enc_steps = encoder_hidden.size(0)\n",
    "    enc_total_size = encoder_hidden.size(2)\n",
    "    enc_attn = self.enc_bilinear(hidden.expand(num_enc_steps, batch_size, -1).contiguous(),encoder_hidden)\n",
    "  \n",
    "    if coverage_vector is not None:\n",
    "        enc_attn += self.cover_weight * torch.log(coverage_vector.transpose(0, 1).unsqueeze(2) + self.eps)\n",
    "    enc_attn = F.softmax(enc_attn, dim=0).transpose(0, 1)\n",
    "\n",
    "    enc_context = torch.bmm(encoder_hidden.permute(1, 2, 0), enc_attn)\n",
    "    combined[:, offset:offset+enc_total_size] = enc_context.squeeze(2)\n",
    "    offset += enc_total_size\n",
    "    enc_attn = enc_attn.squeeze(2)\n",
    "    \n",
    "    if decoder_states is not None and len(decoder_states) > 0:\n",
    "        dec_attn = self.dec_bilinear(hidden.expand_as(decoder_states).contiguous(),\n",
    "                                      decoder_states)\n",
    "        dec_attn = F.softmax(dec_attn, dim=0).transpose(0, 1)\n",
    "        dec_context = torch.bmm(decoder_states.permute(1, 2, 0), dec_attn)\n",
    "        combined[:, offset:offset + self.hidden_size] = dec_context.squeeze(2)\n",
    "        offset += self.hidden_size\n",
    "    \n",
    "    out_embed = combined\n",
    "    logits = self.out(out_embed) \n",
    "\n",
    " \n",
    "    prob_ptr = torch.sigmoid(self.ptr(combined)) \n",
    "    prob_gen = 1 - prob_ptr\n",
    "    gen_output = F.softmax(logits, dim=1)  \n",
    "    output = prob_gen * gen_output\n",
    "    pad_dim = (0, ext_vocab_size - output.size(1))\n",
    "    output=F.pad(output, pad_dim, 'constant')\n",
    "\n",
    "    ptr_output = enc_attn\n",
    "    encoder_word_idx_l = encoder_word_idx.long()\n",
    "    try:\n",
    "        output.scatter_add_(1, encoder_word_idx_l, prob_ptr * ptr_output)\n",
    "    except:\n",
    "        prob_po = prob_ptr * ptr_output \n",
    "        print(output.shape,encoder_word_idx_l.shape,prob_ptr.shape, ptr_output.shape, prob_po.shape)\n",
    "        print(output)\n",
    "        print(encoder_word_idx_l)\n",
    "        print(prob_po)\n",
    "        output.scatter_add_(1, encoder_word_idx_l, prob_po)\n",
    "\n",
    "    output = torch.log(output + self.eps)\n",
    "\n",
    "    return output, hidden, enc_attn, prob_ptr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.521189Z",
     "iopub.status.busy": "2024-01-29T12:02:50.520818Z",
     "iopub.status.idle": "2024-01-29T12:02:50.534128Z",
     "shell.execute_reply": "2024-01-29T12:02:50.533283Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.521153Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_coverage_vector(enc_attn_weights):\n",
    "    \"\"\"Combine the past attention weights into one vector\"\"\"\n",
    "    coverage_vector = torch.sum(torch.cat(enc_attn_weights), dim=0)\n",
    "    \n",
    "    return coverage_vector  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.535751Z",
     "iopub.status.busy": "2024-01-29T12:02:50.535367Z",
     "iopub.status.idle": "2024-01-29T12:02:50.546796Z",
     "shell.execute_reply": "2024-01-29T12:02:50.545872Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.535690Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_batch(data, p, vocab, i, batch_size, device):\n",
    "    ''' Generate and return the next batch of the data during training\n",
    "        Input:\n",
    "        - data: list, input data to the model\n",
    "        - p: a class Parameters object, model and training parameters\n",
    "        - vocab: a class Vocab object, vocabulary of the data\n",
    "        - i: integer, index or iterator\n",
    "        - batch_size: integer, batch size\n",
    "        - device: string, where to train the model, cpu or gpu \n",
    "    '''\n",
    "    vocab_ext=deepcopy(vocab)\n",
    "\n",
    "    try:\n",
    "        data_dict=data[i:i+batch_size]\n",
    "    except:\n",
    "        data_dict=data[i:len(data)]\n",
    "    data_batch = sort_batch_by_len(data_dict,p,vocab_ext)\n",
    "    for word in data_dict['x']:\n",
    "        vocab_ext.add_words(word)\n",
    "\n",
    "    data_batch_extra=sort_batch_by_len(data_dict,p,vocab_ext)    \n",
    "    x_extra=torch.tensor(data_batch_extra['x']).to(device)\n",
    "    \n",
    "    x, x_len = torch.tensor(data_batch['x']).to(device), torch.tensor(data_batch['x_len']).to(device)\n",
    "    y, y_len = torch.tensor(data_batch['y']).to(device), torch.tensor(data_batch['y_len']).to(device)\n",
    "\n",
    "    return x, x_len, y, y_len, x_extra, vocab_ext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.548785Z",
     "iopub.status.busy": "2024-01-29T12:02:50.548375Z",
     "iopub.status.idle": "2024-01-29T12:02:50.614847Z",
     "shell.execute_reply": "2024-01-29T12:02:50.614169Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.548747Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataset,val_dataset,vocab,p,embedding_weights, learning_rate, num_epochs):\n",
    "    ''' Run all the steps in the training phase\n",
    "        Input:\n",
    "        - dataset: Dataset object, training data\n",
    "        - val_dataset: Dataset object, validation data\n",
    "        - vocab: a class Vocab object, the vocabulary of the datasets\n",
    "        - p: a class Parameters object, model and training parameters\n",
    "        - embedding_weigths: tensor, the embedding vectors\n",
    "        - learning_rate: float, learning rate parameter\n",
    "        - num_epochs: integer, number of epochs of the training\n",
    "    '''\n",
    "    eps = p.eps\n",
    "    batch_size =p.batch_size\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    enc_dec_adapter = nn.Linear(p.hidden_size * 2, p.dec_hidden_size).to(DEVICE)\n",
    "    embedding = nn.Embedding(len(vocab), p.embed_size, padding_idx=vocab.PAD,\n",
    "                             _weight=embedding_weights).to(DEVICE)\n",
    "    \n",
    "    embedding.weight.requires_grad=False\n",
    "    encoder = EncoderRNN(p.embed_size, p.hidden_size, p.enc_bidi,rnn_drop=p.enc_rnn_dropout).to(DEVICE)\n",
    "    decoder = DecoderRNN(len(vocab), p.embed_size, p.dec_hidden_size,\n",
    "                                  enc_attn=p.enc_attn, dec_attn=p.dec_attn,\n",
    "                                  pointer=p.pointer,\n",
    "                                  in_drop=p.dec_in_dropout, rnn_drop=p.dec_rnn_dropout,\n",
    "                                  out_drop=p.dec_out_dropout, enc_hidden_size=p.hidden_size * 2,\n",
    "                                  device=DEVICE, epsilon=p.eps).to(DEVICE)\n",
    "\n",
    "    if(os.path.exists(p.encoder_weights_path) and p.resume_train):\n",
    "        encoder.load_state_dict(torch.load(p.encoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    if(os.path.exists(p.decoder_weights_path) and p.resume_train):\n",
    "        decoder.load_state_dict(torch.load(p.decoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    if(os.path.exists(p.encoder_decoder_adapter_weights_path) and p.resume_train):   \n",
    "        enc_dec_adapter.load_state_dict(torch.load(p.encoder_decoder_adapter_weights_path,map_location=torch.device(DEVICE)))\n",
    "    \n",
    "    cnn_data=MyDataset([pair[0] for pair in dataset.pairs],[pair[1] for pair in dataset.pairs],vocab)\n",
    "    \n",
    "    val_data=MyDataset([pair[0] for pair in val_dataset.pairs],[pair[1] for pair in val_dataset.pairs],vocab)\n",
    "    \n",
    "\n",
    "    criterion = nn.NLLLoss(ignore_index=vocab.PAD)\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    adapter_optimizer=optim.Adam([{'params':enc_dec_adapter.parameters()}], lr=learning_rate)\n",
    "    losses=[]\n",
    "    val_losses=[]\n",
    "    if(os.path.exists(p.losses_path) and p.resume_train):\n",
    "        with open(p.losses_path,'rb') as f:\n",
    "        val_losses=pickle.load(f)\n",
    "        \n",
    "    for _e in range(num_epochs):\n",
    "        i=0\n",
    "        print('\\nEpoch: %d/%d' % (_e + 1, num_epochs))\n",
    "        kbar = pkbar.Kbar(target=len(cnn_data), width=8)\n",
    "        while i<len(cnn_data):\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            adapter_optimizer.zero_grad()\n",
    "\n",
    "            x, x_len, y, y_len, x_extra, vocab_ext = get_next_batch(cnn_data, p, vocab, i, batch_size, device=DEVICE)\n",
    "    \n",
    "            encoder_embedded = embedding(x)\n",
    "            encoder_hidden=encoder.init_hidden(x.size(0), DEVICE)\n",
    "            encoder_outputs, encoder_hidden =encoder(encoder_embedded,encoder_hidden,x_len)\n",
    "            decoder_input = torch.tensor([vocab.SOS] * x.size(0), device=DEVICE)\n",
    "            decoder_hidden = enc_dec_adapter(encoder_hidden)\n",
    "            \n",
    "            decoder_states = []\n",
    "            enc_attn_weights = []\n",
    "            loss=0\n",
    "            for di in range(y.size(1)):\n",
    "                decoder_embedded = embedding(decoder_input)\n",
    "                if enc_attn_weights:\n",
    "                    coverage_vector = get_coverage_vector(enc_attn_weights)\n",
    "                else:\n",
    "                    coverage_vector = None\n",
    "                    \n",
    "                decoder_output, decoder_hidden, dec_enc_attn, dec_prob_ptr = decoder(decoder_embedded, decoder_hidden, encoder_outputs,\n",
    "                            torch.cat(decoder_states) if decoder_states else None, coverage_vector,\n",
    "                            encoder_word_idx=x_extra,log_prob=True,ext_vocab_size=len(vocab_ext))  \n",
    "                decoder_output.to(DEVICE)\n",
    "                decoder_hidden.to(DEVICE)\n",
    "                dec_enc_attn.to(DEVICE)\n",
    "                dec_prob_ptr.to(DEVICE)\n",
    "                \n",
    "                decoder_states.append(decoder_hidden)\n",
    "                prob_distribution = torch.exp(decoder_output)\n",
    "                _, top_idx = decoder_output.data.topk(1)\n",
    "                gold_standard = y[:,di]\n",
    "                nll_loss= criterion(decoder_output, gold_standard)    \n",
    "                loss+=nll_loss \n",
    "                decoder_input = y[:,di]\n",
    "                if (coverage_vector is not None and criterion): \n",
    "                    coverage_loss = torch.sum(torch.min(coverage_vector, dec_enc_attn)) / batch_size #* cover_loss            \n",
    "                    loss+=coverage_loss\n",
    "                enc_attn_weights.append(dec_enc_attn.unsqueeze(0)) \n",
    "                \n",
    "            loss.backward()\n",
    "            clip_grad_norm_(encoder.parameters(), 1)\n",
    "            clip_grad_norm_(decoder.parameters(), 1)\n",
    "            clip_grad_norm_(enc_dec_adapter.parameters(), 1)\n",
    "            \n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            adapter_optimizer.step() \n",
    "            \n",
    "            if i%(p.print_every*batch_size)==0:\n",
    "                kbar.update(i, values=[(\"loss\", loss.data.item())])\n",
    "            i+=batch_size\n",
    "               \n",
    "        loss=loss.data.item()/x.size(0)\n",
    "        kbar.add(1, values=[(\"loss\", loss)])\n",
    "        \n",
    "        kbar2 = pkbar.Kbar(target=len(val_data), width=8)\n",
    "        \n",
    "        val_loss=0\n",
    "        i=0\n",
    "        while(i<len(val_data)):\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            adapter_optimizer.zero_grad()\n",
    "            x, x_len, y, y_len, x_extra, vocab_ext = get_next_batch(val_data, p, vocab, i, batch_size, device=DEVICE)\n",
    "            encoder_embedded = embedding(x)\n",
    "            encoder_hidden=encoder.init_hidden(x.size(0), device=DEVICE)\n",
    "            encoder_outputs, encoder_hidden =encoder(encoder_embedded,encoder_hidden,x_len)\n",
    "            decoder_input = torch.tensor([vocab.SOS] * x.size(0), device=DEVICE)\n",
    "            decoder_hidden = enc_dec_adapter(encoder_hidden)\n",
    "            \n",
    "            decoder_states = []\n",
    "            enc_attn_weights = []\n",
    "            for di in range(y.size(1)):\n",
    "                try:\n",
    "                    decoder_embedded = embedding(decoder_input)\n",
    "                except:\n",
    "                    print('Dec input: ',decoder_input.shape,' x:', x.shape,' x_len:',x_len.shape, ' Vocab:', \n",
    "                          vocab.embeddings.shape,' Vocab Ext:', vocab_ext.embeddings.shape)\n",
    "                    decoder_embedded = embedding(decoder_input)\n",
    "\n",
    "                if enc_attn_weights:\n",
    "                    coverage_vector = get_coverage_vector(enc_attn_weights)\n",
    "                else:\n",
    "                    coverage_vector = None\n",
    "                decoder_output, decoder_hidden, dec_enc_attn, dec_prob_ptr = decoder(decoder_embedded, decoder_hidden, encoder_outputs,\n",
    "                            torch.cat(decoder_states) if decoder_states else None, coverage_vector,\n",
    "                            encoder_word_idx=x_extra,log_prob=True,ext_vocab_size=len(vocab_ext))  \n",
    "\n",
    "                decoder_output.to(DEVICE)\n",
    "                decoder_hidden.to(DEVICE)\n",
    "                dec_enc_attn.to(DEVICE)\n",
    "                dec_prob_ptr.to(DEVICE)\n",
    "\n",
    "                decoder_states.append(decoder_hidden)      \n",
    "                prob_distribution = torch.exp(decoder_output)\n",
    "\n",
    "                _, top_idx = decoder_output.data.topk(1)\n",
    "                gold_standard = y[:,di]\n",
    "\n",
    "                nll_loss= criterion(decoder_output, gold_standard)    \n",
    "                val_loss+=nll_loss.data.item()\n",
    "                \n",
    "                decoder_input = top_idx.view(-1) \n",
    "                if (coverage_vector is not None and criterion):\n",
    "                    coverage_loss = torch.sum(torch.min(coverage_vector, dec_enc_attn)) / batch_size #* cover_loss            \n",
    "                    val_loss+=coverage_loss.data.item()\n",
    "                enc_attn_weights.append(dec_enc_attn.unsqueeze(0))  \n",
    "            if i%(p.print_every*batch_size)==0:\n",
    "                kbar2.update(i, values=[(\"Val loss\", val_loss)])\n",
    "\n",
    "            i+=batch_size\n",
    "            \n",
    "        avg_val_loss=val_loss/len(val_data)        \n",
    "        kbar2.add(1, values=[(\"Train loss\", loss), (\"Val loss\", val_loss), (\"Avg Val loss\", avg_val_loss)])\n",
    "        \n",
    "        if(len(val_losses)>0 and avg_val_loss<min(val_losses)):\n",
    "            torch.save(encoder.state_dict(), p.encoder_weights_path)\n",
    "            torch.save(decoder.state_dict(), p.decoder_weights_path)\n",
    "            torch.save(enc_dec_adapter.state_dict(), p.encoder_decoder_adapter_weights_path)\n",
    "        val_losses.append(avg_val_loss) \n",
    "    \n",
    "    with open(p.losses_path,'wb') as f:\n",
    "        pickle.dump(val_losses,f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.616812Z",
     "iopub.status.busy": "2024-01-29T12:02:50.616463Z",
     "iopub.status.idle": "2024-01-29T12:02:50.649183Z",
     "shell.execute_reply": "2024-01-29T12:02:50.648288Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.616776Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(sent,vocab,p,batch_size=1):\n",
    "    ''' Function to predict the summary of the source text sentence\n",
    "        Input:\n",
    "        - sent: string, text to summarize\n",
    "        - vocab: a class Vocab object, vocabulary of the texts\n",
    "        - p: a class Parameters object, model parameters\n",
    "        - batch_size: integer, batch size of the data to predict\n",
    "    '''\n",
    "    eps=p.eps\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    embedding_weights = torch.from_numpy(vocab.embeddings).to(DEVICE)\n",
    "    enc_dec_adapter = nn.Linear(p.hidden_size * 2, p.dec_hidden_size).to(DEVICE)\n",
    "    embedding = nn.Embedding(len(vocab), p.embed_size, padding_idx=vocab.PAD,_weight=embedding_weights).to(DEVICE)\n",
    "    encoder = EncoderRNN(p.embed_size, p.hidden_size, p.enc_bidi,rnn_drop=p.enc_rnn_dropout).to(DEVICE)\n",
    "    decoder = DecoderRNN(len(vocab), p.embed_size, p.dec_hidden_size,\n",
    "                                  enc_attn=p.enc_attn, dec_attn=p.dec_attn,\n",
    "                                  pointer=p.pointer,\n",
    "                                  in_drop=p.dec_in_dropout, rnn_drop=p.dec_rnn_dropout,\n",
    "                                  out_drop=p.dec_out_dropout, enc_hidden_size=p.hidden_size * 2,\n",
    "                                  device=DEVICE).to(DEVICE) \n",
    "    sent_vec=[vocab[word] for word in sent.split()]\n",
    "    vocab_ext=deepcopy(vocab)\n",
    "    for word in sent.split():\n",
    "        vocab_ext.add_words(word)\n",
    "    sent_vec_extra=[vocab_ext[word] for word in sent.split()] \n",
    "    if(len(sent_vec_extra)<p.max_src_len):\n",
    "        pad_dim = (0, p.max_src_len-len(sent_vec_extra))\n",
    "        sent_vec_extra_tensor=F.pad(torch.tensor(sent_vec_extra), pad_dim , 'constant')\n",
    "    else:\n",
    "        sent_vec_extra_tensor=torch.tensor(sent_vec_extra)\n",
    "        \n",
    "    if(len(sent_vec)<p.max_src_len):\n",
    "        pad_dim = (0, p.max_src_len-len(sent_vec))\n",
    "        sent_vec_tensor=F.pad(torch.tensor(sent_vec), pad_dim, 'constant')\n",
    "    else:\n",
    "        sent_vec_tensor=torch.tensor(sent_vec)\n",
    "        \n",
    "    if(os.path.exists(p.encoder_weights_path)):\n",
    "        encoder.load_state_dict(torch.load(p.encoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    if(os.path.exists(p.decoder_weights_path)):\n",
    "        decoder.load_state_dict(torch.load(p.decoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    if(os.path.exists(p.encoder_decoder_adapter_weights_path)):    \n",
    "        enc_dec_adapter.load_state_dict(torch.load(p.encoder_decoder_adapter_weights_path,map_location=torch.device(DEVICE)))\n",
    "\n",
    "    x=sent_vec_tensor.view(1,-1).to(DEVICE)\n",
    "    x_extra=sent_vec_extra_tensor.view(1,-1).to(DEVICE)\n",
    "    encoder_embedded = embedding(x)\n",
    "    encoder_hidden=encoder.init_hidden(x.size(0), DEVICE)\n",
    "    encoder_outputs, encoder_hidden =encoder(encoder_embedded,encoder_hidden,\n",
    "                                             torch.tensor(p.max_src_len).view(1).to(DEVICE))\n",
    "    decoder_input = torch.tensor([vocab.SOS] * batch_size, device=DEVICE)\n",
    "    decoder_hidden = enc_dec_adapter(encoder_hidden)\n",
    "    \n",
    "    decoder_states = []\n",
    "    enc_attn_weights = []\n",
    "    output=[]\n",
    "    for di in range(p.max_tgt_len):\n",
    "        decoder_embedded = embedding(decoder_input)\n",
    "        if enc_attn_weights:\n",
    "            coverage_vector = get_coverage_vector(enc_attn_weights)\n",
    "        else:\n",
    "            coverage_vector = None\n",
    "        decoder_output, decoder_hidden, dec_enc_attn, dec_prob_ptr = decoder(decoder_embedded, decoder_hidden, encoder_outputs,\n",
    "                    torch.cat(decoder_states).to(DEVICE) if decoder_states else None, coverage_vector,\n",
    "                    encoder_word_idx=x_extra,log_prob=True,ext_vocab_size=len(vocab_ext))  \n",
    "        decoder_output.to(DEVICE)\n",
    "        decoder_hidden.to(DEVICE)\n",
    "        dec_enc_attn.to(DEVICE)\n",
    "        dec_prob_ptr.to(DEVICE)\n",
    "        decoder_states.append(decoder_hidden)\n",
    "        prob_distribution = torch.exp(decoder_output)\n",
    "        _, top_idx = decoder_output.data.topk(1)\n",
    "        output.append(top_idx.squeeze().data.item())\n",
    "        enc_attn_weights.append(dec_enc_attn.unsqueeze(0))\n",
    "        decoder_input = top_idx.view(-1)\n",
    "    output=[vocab_ext[idx] for idx in output]    \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.650775Z",
     "iopub.status.busy": "2024-01-29T12:02:50.650412Z",
     "iopub.status.idle": "2024-01-29T12:02:50.674568Z",
     "shell.execute_reply": "2024-01-29T12:02:50.673860Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.650727Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(sent,vocab,embedding, encoder, enc_dec_adapter, decoder, device, p,batch_size=1):\n",
    "    ''' Function to predict the summary of the source text sentence\n",
    "        Input:\n",
    "        - sent: string, text to summarize\n",
    "        - vocab: a class Vocab object, vocabulary of the texts\n",
    "        - p: a class Parameters object, model parameters\n",
    "        - batch_size: integer, batch size of the data to predict\n",
    "    '''\n",
    "    eps=p.eps\n",
    "    sent_vec=[vocab[word] for word in sent.split()]\n",
    "    vocab_ext=deepcopy(vocab)\n",
    "    for word in sent.split():\n",
    "        vocab_ext.add_words(word)\n",
    "    sent_vec_extra=[vocab_ext[word] for word in sent.split()] \n",
    "    if(len(sent_vec_extra)<p.max_src_len):\n",
    "        pad_dim = (0, p.max_src_len-len(sent_vec_extra))\n",
    "        sent_vec_extra_tensor=F.pad(torch.tensor(sent_vec_extra), pad_dim , 'constant')\n",
    "    else:\n",
    "        sent_vec_extra_tensor=torch.tensor(sent_vec_extra)\n",
    "        \n",
    "    if(len(sent_vec)<p.max_src_len):\n",
    "        pad_dim = (0, p.max_src_len-len(sent_vec))\n",
    "        sent_vec_tensor=F.pad(torch.tensor(sent_vec), pad_dim, 'constant')\n",
    "    else:\n",
    "        sent_vec_tensor=torch.tensor(sent_vec)\n",
    "        \n",
    "    x=sent_vec_tensor.view(1,-1).to(device)\n",
    "    x_extra=sent_vec_extra_tensor.view(1,-1).to(device)\n",
    "    encoder_embedded = embedding(x)\n",
    "    encoder_hidden=encoder.init_hidden(x.size(0), device)\n",
    "    encoder_outputs, encoder_hidden =encoder(encoder_embedded,encoder_hidden,\n",
    "                                             torch.tensor(p.max_src_len).view(1).to(device))\n",
    "    decoder_input = torch.tensor([vocab.SOS] * batch_size, device=device)\n",
    "    decoder_hidden = enc_dec_adapter(encoder_hidden)\n",
    "    \n",
    "    decoder_states = []\n",
    "    enc_attn_weights = []\n",
    "    output=[]\n",
    "    for di in range(p.max_tgt_len):\n",
    "        decoder_embedded = embedding(decoder_input)\n",
    "        if enc_attn_weights:\n",
    "            coverage_vector = get_coverage_vector(enc_attn_weights)\n",
    "        else:\n",
    "            coverage_vector = None\n",
    "            \n",
    "        decoder_output, decoder_hidden, dec_enc_attn, dec_prob_ptr = decoder(decoder_embedded, decoder_hidden, encoder_outputs,\n",
    "                    torch.cat(decoder_states).to(device) if decoder_states else None, coverage_vector,\n",
    "                    encoder_word_idx=x_extra,log_prob=True,ext_vocab_size=len(vocab_ext))  \n",
    "        decoder_output.to(device)\n",
    "        decoder_hidden.to(device)\n",
    "        dec_enc_attn.to(device)\n",
    "        dec_prob_ptr.to(device)\n",
    "        decoder_states.append(decoder_hidden)\n",
    "        prob_distribution = torch.exp(decoder_output)\n",
    "        _, top_idx = decoder_output.data.topk(1)\n",
    "        output.append(top_idx.squeeze().data.item())\n",
    "        enc_attn_weights.append(dec_enc_attn.unsqueeze(0))\n",
    "        decoder_input = top_idx.view(-1)\n",
    "        \n",
    "    output=[vocab_ext[idx] for idx in output]    \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.676219Z",
     "iopub.status.busy": "2024-01-29T12:02:50.675814Z",
     "iopub.status.idle": "2024-01-29T12:02:50.692069Z",
     "shell.execute_reply": "2024-01-29T12:02:50.691219Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.676174Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_metrics(preds, targets, avg=True):\n",
    "    ''' Evaluate the ROUGE metrics ROUGE-2 and ROUGE-L for every pair predicted summary - target summary\n",
    "    \n",
    "        Input:\n",
    "           - preds: list of strings, predicted summaries\n",
    "           - targets: list of string, target summaries\n",
    "        Output:\n",
    "            - rouge2_f_metric: list of float, the Rouge-2 fscore for every predicted summary\n",
    "            - rougel_f_metric: list of float, the Rouge-L fscore for every predicted summary\n",
    "    '''\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(preds, targets, avg)\n",
    "    if avg:\n",
    "        rouge2_f_metric = scores['rouge-2']['f']\n",
    "        rouge2_p_metric = scores['rouge-2']['p']\n",
    "        rouge2_r_metric = scores['rouge-2']['r']\n",
    "        rougel_f_metric = scores['rouge-l']['f']\n",
    "        rougel_p_metric = scores['rouge-l']['p']\n",
    "        rougel_r_metric = scores['rouge-l']['r']\n",
    "    else:\n",
    "        rouge2_f_metric = [score['rouge-2']['f'] for score in scores]\n",
    "        rouge2_p_metric = [score['rouge-2']['p'] for score in scores]\n",
    "        rouge2_r_metric = [score['rouge-2']['r'] for score in scores]\n",
    "        rougel_f_metric = [score['rouge-l']['f'] for score in scores]\n",
    "        rougel_p_metric = [score['rouge-l']['p'] for score in scores]\n",
    "        rougel_r_metric = [score['rouge-l']['r'] for score in scores]\n",
    "    \n",
    "    return rouge2_f_metric, rouge2_p_metric, rouge2_r_metric, rougel_f_metric, rougel_p_metric, rougel_r_metric\n",
    "\n",
    "def save_to_df(text, labeled_summaries, predicted_summaries, r2_f, r2_p, r2_r, rl_f, rl_p, rl_r):\n",
    "    ''' Stores the metric results into a pandas dataframe'''\n",
    "    results = pd.DataFrame(columns=['text', 'summary','pred_summary','rouge2-f','rouge2-p','rouge2-r','rougel-f', 'rougel-p', 'rougel-r'])\n",
    "    results['text'] = text\n",
    "    results['summary'] = labeled_summaries\n",
    "    results['pred_summary'] = predicted_summaries\n",
    "    results['rouge2-f'] = r2_f\n",
    "    results['rouge2-p'] = r2_p\n",
    "    results['rouge2-r'] = r2_r\n",
    "    results['rougel-f'] = rl_f\n",
    "    results['rougel-p'] = rl_p\n",
    "    results['rougel-r'] = rl_r\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.693457Z",
     "iopub.status.busy": "2024-01-29T12:02:50.693178Z",
     "iopub.status.idle": "2024-01-29T12:02:50.711683Z",
     "shell.execute_reply": "2024-01-29T12:02:50.710975Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.693425Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(x_test, vocab, params, print_every=20):\n",
    "    ''' Generate the predicted summaries of the source texts on x_test\n",
    "        Input:\n",
    "        - x_test: list of strings, the source texts\n",
    "        - vocab: a Vocab Class object, vocabulary of the texts\n",
    "        - params: a Parameters object, parameter of the model\n",
    "        - print_every: integer, print progress every print_every iterations\n",
    "    '''\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    embedding_weights = torch.from_numpy(vocab.embeddings).to(DEVICE)\n",
    "    enc_dec_adapter = nn.Linear(params.hidden_size * 2, params.dec_hidden_size).to(DEVICE)\n",
    "    embedding = nn.Embedding(len(vocab), params.embed_size, padding_idx=vocab.PAD,_weight=embedding_weights).to(DEVICE)\n",
    "    encoder = EncoderRNN(params.embed_size,params.hidden_size, params.enc_bidi,rnn_drop=params.enc_rnn_dropout).to(DEVICE)\n",
    "    decoder = DecoderRNN(len(vocab), params.embed_size, params.dec_hidden_size,\n",
    "                                  enc_attn=params.enc_attn, dec_attn=params.dec_attn,\n",
    "                                  pointer=params.pointer,\n",
    "                                  in_drop=params.dec_in_dropout, rnn_drop=params.dec_rnn_dropout,\n",
    "                                  out_drop=params.dec_out_dropout, enc_hidden_size=params.hidden_size * 2,\n",
    "                                  device=DEVICE).to(DEVICE) \n",
    "\n",
    "    if(os.path.exists(params.encoder_weights_path)):\n",
    "        encoder.load_state_dict(torch.load(params.encoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    if(os.path.exists(params.decoder_weights_path)):\n",
    "        decoder.load_state_dict(torch.load(params.decoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    if(os.path.exists(params.encoder_decoder_adapter_weights_path)):    \n",
    "        enc_dec_adapter.load_state_dict(torch.load(params.encoder_decoder_adapter_weights_path,map_location=torch.device(DEVICE)))\n",
    "\n",
    "        \n",
    "    predicted_summaries = []\n",
    "    kbar = pkbar.Kbar(target=len(x_test), width=8)\n",
    "    for i,doc in enumerate(x_test):\n",
    "        pred_summ = prediction(doc,vocab,embedding,encoder,enc_dec_adapter,decoder,DEVICE,params,batch_size=1)\n",
    "        predicted_summaries.append(' '.join(pred_summ))\n",
    "        if i%print_every==0:\n",
    "            kbar.update(i)\n",
    "            \n",
    "    return predicted_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.713129Z",
     "iopub.status.busy": "2024-01-29T12:02:50.712807Z",
     "iopub.status.idle": "2024-01-29T12:02:50.725187Z",
     "shell.execute_reply": "2024-01-29T12:02:50.724212Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.713102Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_predictions(x_test, vocab, params, print_every=20):\n",
    "    ''' Generate the predicted summaries of the source texts on x_test\n",
    "        Input:\n",
    "        - x_test: list of strings, the source texts\n",
    "        - vocab: a Vocab Class object, vocabulary of the texts\n",
    "        - params: a Parameters object, parameter of the model\n",
    "        - print_every: integer, print progress every print_every iterations\n",
    "    '''\n",
    "\n",
    "    predicted_summaries = []\n",
    "\n",
    "    kbar = pkbar.Kbar(target=len(x_test), width=8)\n",
    "\n",
    "    for i,doc in enumerate(x_test):\n",
    "\n",
    "        pred_summ = predict(doc,vocab,params,batch_size=1)\n",
    "        predicted_summaries.append(' '.join(pred_summ))\n",
    " \n",
    "        if i%print_every==0:\n",
    "            kbar.update(i)\n",
    "            \n",
    "   \n",
    "    return predicted_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.726802Z",
     "iopub.status.busy": "2024-01-29T12:02:50.726447Z",
     "iopub.status.idle": "2024-01-29T12:02:50.738130Z",
     "shell.execute_reply": "2024-01-29T12:02:50.737312Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.726766Z"
    }
   },
   "outputs": [],
   "source": [
    "params = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:50.739577Z",
     "iopub.status.busy": "2024-01-29T12:02:50.739223Z",
     "iopub.status.idle": "2024-01-29T12:02:51.993757Z",
     "shell.execute_reply": "2024-01-29T12:02:51.992750Z",
     "shell.execute_reply.started": "2024-01-29T12:02:50.739539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset /kaggle/input/cleaned-news-summary/cl_train_news_summary_more.csv... 64000 pairs.\n",
      "Reading dataset /kaggle/input/cleaned-news-summary/cl_train_news_summary_more.csv... 3200 pairs.\n",
      "61 54 14 13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = Dataset(params.data_path, simple_tokenizer, params.max_src_len, params.max_tgt_len, max_rows=64000,\n",
    "                        truncate_src=True, truncate_tgt=True)\n",
    "valid_dataset = Dataset(params.val_data_path, simple_tokenizer, params.max_src_len, params.max_tgt_len, max_rows= 3200,\n",
    "                        truncate_src=True, truncate_tgt=True)\n",
    "print(dataset.src_len, valid_dataset.src_len,dataset.tgt_len, valid_dataset.tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:51.995224Z",
     "iopub.status.busy": "2024-01-29T12:02:51.994941Z",
     "iopub.status.idle": "2024-01-29T12:02:59.051170Z",
     "shell.execute_reply": "2024-01-29T12:02:59.050230Z",
     "shell.execute_reply.started": "2024-01-29T12:02:51.995196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29022 pre-trained embeddings loaded.\n"
     ]
    }
   ],
   "source": [
    "vocab = dataset.build_vocab(params.vocab_min_frequency, embed_file=params.embed_file)\n",
    "vocab.save_to_file('vocab_train.pkl')\n",
    "embedding_weights = torch.from_numpy(vocab.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T12:02:59.057618Z",
     "iopub.status.busy": "2024-01-29T12:02:59.057202Z",
     "iopub.status.idle": "2024-01-29T16:03:30.572061Z",
     "shell.execute_reply": "2024-01-29T16:03:30.571135Z",
     "shell.execute_reply.started": "2024-01-29T12:02:59.057562Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/10\n",
      "1601/3200 [===>....] - ETA: 50s - Val loss: 5743.1058 - Train loss: 2.8980 - Avg Val loss: 3.5510\n",
      "Epoch: 2/10\n",
      "1601/3200 [===>....] - ETA: 53s - Val loss: 5731.3381 - Train loss: 2.5627 - Avg Val loss: 3.5395\n",
      "Epoch: 3/10\n",
      "1601/3200 [===>....] - ETA: 53s - Val loss: 5797.5375 - Train loss: 2.3181 - Avg Val loss: 3.5613\n",
      "Epoch: 4/10\n",
      "1601/3200 [===>....] - ETA: 53s - Val loss: 5668.7522 - Train loss: 2.0249 - Avg Val loss: 3.5443\n",
      "Epoch: 5/10\n",
      "1601/3200 [===>....] - ETA: 55s - Val loss: 5768.4707 - Train loss: 1.8409 - Avg Val loss: 3.5840\n",
      "Epoch: 6/10\n",
      "1601/3200 [===>....] - ETA: 56s - Val loss: 5762.2783 - Train loss: 1.7314 - Avg Val loss: 3.5798\n",
      "Epoch: 7/10\n",
      "1601/3200 [===>....] - ETA: 54s - Val loss: 5787.8225 - Train loss: 1.7196 - Avg Val loss: 3.5747\n",
      "Epoch: 8/10\n",
      "1601/3200 [===>....] - ETA: 55s - Val loss: 5756.4203 - Train loss: 1.6308 - Avg Val loss: 3.6272\n",
      "Epoch: 9/10\n",
      "1601/3200 [===>....] - ETA: 55s - Val loss: 5874.0652 - Train loss: 1.6695 - Avg Val loss: 3.6691\n",
      "Epoch: 10/10\n",
      "1601/3200 [===>....] - ETA: 55s - Val loss: 5833.0908 - Train loss: 1.5423 - Avg Val loss: 3.6748"
     ]
    }
   ],
   "source": [
    "train(dataset,valid_dataset,vocab, params, embedding_weights,learning_rate=0.001,num_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test dataset to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T16:03:30.574383Z",
     "iopub.status.busy": "2024-01-29T16:03:30.574030Z",
     "iopub.status.idle": "2024-01-29T16:17:44.671176Z",
     "shell.execute_reply": "2024-01-29T16:17:44.670221Z",
     "shell.execute_reply.started": "2024-01-29T16:03:30.574350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset /kaggle/input/cleaned-news-summary/cl_valid_news_summary_more.csv... 3200 pairs.\n",
      "Length Test Dataset: 3200\n",
      "3100/3200 [======>.] - ETA: 26s\n",
      "Mean Rouge-2 FScore:  0.12921766904371598 Mean Rouge-L FScore:  0.331027675203172\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>pred_summary</th>\n",
       "      <th>rouge2-f</th>\n",
       "      <th>rouge2-p</th>\n",
       "      <th>rouge2-r</th>\n",
       "      <th>rougel-f</th>\n",
       "      <th>rougel-p</th>\n",
       "      <th>rougel-r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hrd ministry formed threemember special invest...</td>\n",
       "      <td>govt forms sit ryan murder case cbse seeks saf...</td>\n",
       "      <td>hrd ministry formed sit probe murder sevenyear...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>letter written jail sheena bora murder accused...</td>\n",
       "      <td>indrani asks furniture jewellery divorce report</td>\n",
       "      <td>indrani mukerjea asks furniture jewellery artw...</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enforcement directorate ed friday conducted se...</td>\n",
       "      <td>ed raids 35 premises nirav modi  assets seized</td>\n",
       "      <td>ed raids new locations fraudaccused diamond je...</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>japan acknowledged first time worker died radi...</td>\n",
       "      <td>japan admits 1st death 2011 fukushima nuclear ...</td>\n",
       "      <td>japan acknowledged first time worker died nucl...</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entire village germany auctioned weekend bids ...</td>\n",
       "      <td>entire village germany auctioned</td>\n",
       "      <td>village germany auctioned weekend bids  crore...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  hrd ministry formed threemember special invest...   \n",
       "1  letter written jail sheena bora murder accused...   \n",
       "2  enforcement directorate ed friday conducted se...   \n",
       "3  japan acknowledged first time worker died radi...   \n",
       "4  entire village germany auctioned weekend bids ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  govt forms sit ryan murder case cbse seeks saf...   \n",
       "1    indrani asks furniture jewellery divorce report   \n",
       "2    ed raids 35 premises nirav modi  assets seized   \n",
       "3  japan admits 1st death 2011 fukushima nuclear ...   \n",
       "4                   entire village germany auctioned   \n",
       "\n",
       "                                        pred_summary  rouge2-f  rouge2-p  \\\n",
       "0  hrd ministry formed sit probe murder sevenyear...  0.000000  0.000000   \n",
       "1  indrani mukerjea asks furniture jewellery artw...  0.210526  0.142857   \n",
       "2  ed raids new locations fraudaccused diamond je...  0.095238  0.076923   \n",
       "3  japan acknowledged first time worker died nucl...  0.095238  0.071429   \n",
       "4  village germany auctioned weekend bids  crore...  0.250000  0.153846   \n",
       "\n",
       "   rouge2-r  rougel-f  rougel-p  rougel-r  \n",
       "0  0.000000  0.190476  0.181818  0.200000  \n",
       "1  0.400000  0.500000  0.357143  0.833333  \n",
       "2  0.125000  0.285714  0.250000  0.333333  \n",
       "3  0.142857  0.285714  0.230769  0.375000  \n",
       "4  0.666667  0.375000  0.250000  0.750000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset(params.test_data_path, simple_tokenizer, params.max_src_len, params.max_tgt_len, max_rows= 3200,\n",
    "                        truncate_src=True, truncate_tgt=True)\n",
    "print('Length Test Dataset:', len(test_dataset.pairs))\n",
    "x_test = [' '.join(pair[0]) for pair in test_dataset.pairs]\n",
    "y_test = [' '.join(pair[1]) for pair in test_dataset.pairs]\n",
    "preds = get_predictions(x_test, vocab, params, print_every=100)\n",
    "r2_f, r2_p, r2_r, rl_f, rl_p, rl_r = eval_metrics(preds, y_test, False)\n",
    "print('\\nMean Rouge-2 FScore: ',np.mean(r2_f), 'Mean Rouge-L FScore: ',np.mean(rl_f))\n",
    "test_results = save_to_df(x_test, y_test, preds, r2_f, r2_p, r2_r, rl_f, rl_p, rl_r)\n",
    "test_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T16:24:07.809468Z",
     "iopub.status.busy": "2024-01-29T16:24:07.809069Z",
     "iopub.status.idle": "2024-01-29T16:24:07.814712Z",
     "shell.execute_reply": "2024-01-29T16:24:07.813671Z",
     "shell.execute_reply.started": "2024-01-29T16:24:07.809435Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_rouge(y_test, preds):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(preds, y_test, avg=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T16:24:58.429613Z",
     "iopub.status.busy": "2024-01-29T16:24:58.429217Z",
     "iopub.status.idle": "2024-01-29T16:24:59.401860Z",
     "shell.execute_reply": "2024-01-29T16:24:59.400753Z",
     "shell.execute_reply.started": "2024-01-29T16:24:58.429582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge-1': {'r': 0.5022704274891789, 'p': 0.29198233450577155, 'f': 0.3656299544703699}, 'rouge-2': {'r': 0.2001990327380952, 'p': 0.0967695811133316, 'f': 0.12921766904371532}, 'rouge-l': {'r': 0.4546986268939392, 'p': 0.2643932855339099, 'f': 0.33102767520317194}}\n"
     ]
    }
   ],
   "source": [
    "rouge_scores = calculate_rouge(y_test, preds)\n",
    "print(f\"ROUGE Scores: {rouge_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 658732,
     "sourceId": 1179431,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 715814,
     "sourceId": 1246668,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29928,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
